from fastapi import FastAPI
from fastapi.responses import Response
import torch
import os
import sys
from torchvision.io import encode_png

project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.insert(0, project_root)

from models.WGAN_GP.WGAN_GP import Generator


def unnormalise_image(norm_image: torch.Tensor) -> torch.Tensor:
    """Convert an image Tensor with values in range (-1, 1) to an image Tensor with values in range (0, 255)

    Args:
        norm_image (torch.Tensor): A normalised image tensor, usually an output from generator

    Returns:
        torch.Tensor: The unnormalised image Tensor
    """
    # Change from range (-1, 1) to range (0 ,1)
    image = (norm_image + 1) / 2
    # Change from range (0, 1) to range (0, 255)
    image = image * 255

    return image


def tensor_to_bytes(image_tensor: torch.Tensor) -> bytes:
    """Convert a tensor representing an image to bytes of an image

    Args:
        image_tensor (torch.Tensor): A tensor of shape [C, H, W] representing an image

    Returns:
        bytes: Bytes of the image
    """
    # Convert the tensor values to be int8
    image_tensor = image_tensor.to(torch.uint8)
    # Convert to a one dimensional int8 tensor containing raw bytes
    raw_bytes = encode_png(image_tensor)
    # Convert to bytes
    img_bytes = bytes(raw_bytes)

    return img_bytes


def generate_image_bytes(img_generator: Generator) -> bytes:
    """Generate an image bytes from a given generator

    Args:
        img_generator (Generator): WGAN generator to generate image tensor

    Returns:
        bytes: Bytes of a a generated image.
    """
    # Noise for input to the generator
    noise = torch.randn(1, 100)
    # Generate one image from the generator
    with torch.no_grad():
        normalised_image = generator(noise)[0]
    # Unnormalise the image tensor
    image = unnormalise_image(normalised_image)
    # Convert the image tensor to bytes
    png_bytes = tensor_to_bytes(image)

    return png_bytes


app = FastAPI(
    title="WGAN-GP API",
    description="API for generating images of human faces using trained WGAN-GP generator",
    version="1.0.0",
)

generator = Generator(noise_dim=100, final_conv_size=128, output_channels=3)

generator.load_state_dict(
    torch.load("parameters/WGAN-GP-250epochs/generator.pth", weights_only=True)
)

generator.eval()


@app.get(
    "/image",
    responses={200: {"content": {"image/png": {}}}},
    response_class=Response,
    summary="Generate image",
    description="Returns an image png generated by our WGAN-GP model",
)
def get_image():
    image_bytes = generate_image_bytes(generator)

    return Response(content=image_bytes, media_type="image/png")
